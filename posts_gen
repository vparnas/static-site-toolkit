#!/bin/bash

# TODO use CFG_FILE vars for output directory, file names, etc
# TODO: consolidate ssg with posts_gen. Or not? Use the same config?
[ -z "$CFG_FILE" ] && CFG_FILE="./.ssg_config"
[ -f "$CFG_FILE" ] && . "$CFG_FILE" # source config file if available
sep="#"

function name_linkify
{
	echo "$1" | awk '{print gensub("[[:space:]]", "-", "g", tolower($0))}'
}

# TODO: configurable to select the category html name format (include extension in link?)
function gen_categories_htmls
{
	markdown_list="$1"; shift
	out_dir="$1"; shift
	main_html="$1"; shift
	[ -n "$out_dir" ] && out_dir="${out_dir%/}" || out_dir=""
	[ -n "$main_html" ] && main_html="$out_dir/""$main_html" || main_html="$out_dir/""categories.html"

	echo -e "<h1>Categories</h1>\n<ul>" > "$main_html"
	cats_counts=$(sed '1d' "$markdown_list" | awk -F "$sep" '{if ($5) print $5}' | sort | uniq -ci)
	while read -r count cat; do
		fname="$out_dir/"$(name_linkify "$cat")
		echo "Generating $fname.html"
		gen_archives_html "$markdown_list" "$cat" > "$fname.html"
		echo "<li><a href='/$fname/'>$cat</a> ($count)</li>" >> "$main_html"
	done <<< "$cats_counts"
	echo "</ul>" >> "$main_html"
	echo "Generating $main_html"
}

# Generate an archives file for all or specific category
# $1: posts CSV
# $2: (optional) category
function gen_archives_html
{
	markdown_list="$1"; shift
	cat="$1"; shift
	# TODO: category link in lowercase one-word format 
	[ -z "$cat" ] && echo "<h1>Archives</h1>" || echo "<h1>$cat category</h1>"
	echo "<p>"
	sed '1d' "$markdown_list" | awk -F "$sep" -v cat="$cat" \
		'{if ($1 && (!cat || tolower($5) == tolower(cat)))\
			{print ""$1" | <a href=\""$4"\" title=\""$3"\">"$3"</a>";\
			if (!cat) print " | Category: "$5; print "<br/>"}}'
	echo "</p>"
	
}

function gen_index_html
{
	markdown_list="$1"; shift
	# TODO: category link in lowercase one-word format 
	echo "<h2>All Articles</h2>"
	sed '1d' "$markdown_list" | awk -F "$sep" '{if ($1) {print \
"<article class=\"hentry\">\n\
	<header><h2 class=\"entry-title\">\n\
		<a href=\""$4"\" title=\""$3"\">"$3"</a></h2>\n\
	</header>\n\
	<footer class=\"post-info\">\n\
		<time class=\"published\" datetime=\""$1"\">"$1"</time>"; \
	if ($5) print "\
		| Category: "$5; print "\
	</footer>\n</article>\n"}}'
}

# TODO: generate for more than just markdown files
function gen_sitemap
{
	markdown_list="$1"; shift
	site_url="$1"; shift
    cat <<EOF
<?xml version="1.0" encoding="UTF-8"?>
<urlset xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
xsi:schemaLocation="http://www.sitemaps.org/schemas/sitemap/0.9
http://www.sitemaps.org/schemas/sitemap/0.9/sitemap.xsd"
xmlns="http://www.sitemaps.org/schemas/sitemap/0.9">
EOF
	IFS="#"
	sed '1d' "$markdown_list" |
	while read -r d m _ h _ _; do
        if [ -n "$m" ]; then
			lastmod="$m" 
		elif [ -n "$d" ]; then
			lastmod="$d"
		else # TODO: Assign other than present date?
			lastmod="$(date '+%Y-%m-%d')"
		fi
		echo "<url><loc>$site_url$h</loc><lastmod>$lastmod</lastmod><priority>1.0</priority></url>"
	done

	echo "</urlset>"
}

# TODO: rather than the first <p> tag, leverage first 30 characters?
function get_description
{
	start='sub("^.*<"s"*"t"("s"[^>]*)?>","")'
	stop='sub("</"s"*"t""s"*>.*","") && x=1'
	awk -v 's=[[:space:]]' -v 't=[Pp]' "$start,$stop;x{exit}"
}

function remove_tags
{
	sed 's#<[^>]*>##g;s#</[^>]*>##g'
}

function remove_nbsp
{
	sed 's#\&nbsp;# #g'
}

function gen_rss
{
	markdown_list="$1"; shift
	html_dir="$1"; shift
	site_title="$1"; shift
	site_url="$1"; shift
	build_date=$(date '+%a, %d %b %Y %H:%M:%S %z')

	[ ! -d "$html_dir" ] && echo "directory $html_dir nonexistant" && return

	cat <<EOF  
<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"><channel>
	<title>$site_title</title>
	<link>$site_url</link>
	<description></description>
	<lastBuildDate>$build_date</lastBuildDate>
EOF

	IFS="#"
	sed '1d' "$markdown_list" |
	while read -r d m t h c s; do
		[ -z "$d" ] && continue
		post_date=$(date '+%a, %d %b %Y %H:%M:%S %z' -d "$d")
		site_url_no_lead="${site_url##*/}"
		if [ -n "$s" ]; then 
            summary="$s"
        else
			html_path="$html_dir/$h"
			[ -z "${html_path##*/}" ] && html_path="$html_path""index.html"
			summary=$(get_description < "$html_path" |
				remove_tags | remove_nbsp )
        fi
		cat <<EOF
	<item>
		<title>$t</title>
		<link>$site_url$h</link>
		<description><![CDATA[
		$summary
		]]></description>
		<dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">$site_title</dc:creator>
		<pubDate>$post_date</pubDate>
		<guid isPermaLink="false">tag:$site_url_no_lead,$d:$h</guid>
	</item>
EOF
	done

	cat <<EOF
</channel></rss>
EOF
}

# TODO: generate for more than just markdown files
function gen_markdown_csv_list
{
	echo "date"$sep"modified"$sep"title"$sep"href"$sep"category"$sep"summary"
	cd "$1" && find -L . -iregex '.*\.md' -type f -exec awk -v sep="$sep" '
	BEGIN {IGNORECASE=1; FS=":[[:space:]]*"}
		/^date:/{d=$2} 
		/^modified:/{m=$2} 
		/^title:/{t=$2} 
		/^category:/{c=$2} 
		/^summary:/{s=$2} 
		/^status:/{st=$2} 
		/^\s*$/{nextfile}
	END {
	if (st ~ /draft/) exit;
	href=FILENAME;
	sub("\\.md$", "/", href);
	sub("^\\.", "", href); 
	print d sep m sep t sep href sep c sep s}' {} \; | sort -rn
}

function help
{
	echo "-c <dir path>: generate generic CSV"
	echo "-a <csv> [category]: generate archives file"
	echo "-i <csv>: generate index file"
	echo "-r <csv> <html dir> <site title> <site url>: generate rss"
	echo "-m <csv> <site url>: generate site map"
	echo "-C <csv> [rel output dir] [categories.html] : generate categories indices"
	echo "-h: this help"
}

[ -n "$1" ] && [ -z "$2" ] && help && exit 1

while getopts "achiCrm" o; do 
    case "${o}" in
        a) gen_archives_html "${@:2}"; exit 0;;
        c) gen_markdown_csv_list "$2"; exit 0;;
        C) gen_categories_htmls "${@:2}"; exit 0;;
        i) gen_index_html "$2"; exit 0;;
        r) [ -n "$5" ] && gen_rss "${@:2}" || help; exit 0;;
        m) [ -n "$3" ] && gen_sitemap "${@:2}" || help; exit 0;;
        h|*) help; exit 0;;
    esac 
done

help
